import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os
from datetime import datetime, timedelta
from typing import Dict, List, Tuple

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'  # macOSìš©
# plt.rcParams['font.family'] = 'Malgun Gothic' # Windowsìš©
plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

class TimeSeriesAnalyzer:
    def __init__(self):
        # ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì • (ë” ì•ˆì •ì )
        script_dir = os.path.dirname(os.path.abspath(__file__))
        self.database_path = os.path.join(script_dir, "..", "database")
        self.results = {}
        
    def load_preprocessed_files(self) -> Dict[str, pd.DataFrame]:
        """ì „ì²˜ë¦¬ëœ íŒŒì¼ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        files = {
            'IMDB': 'preprocessed_reviews_imdb.csv',
            'Metacritic': 'preprocessed_reviews_metacritic.csv', 
            'Rotten Tomatoes': 'preprocessed_reviews_rottentomatoes.csv'
        }
        
        dataframes = {}
        for site_name, filename in files.items():
            file_path = os.path.join(self.database_path, filename)
            if os.path.exists(file_path):
                try:
                    df = pd.read_csv(file_path)
                    dataframes[site_name] = df
                    print(f"âœ… {site_name}: {len(df)} ë¦¬ë·° ë¡œë“œë¨")
                except Exception as e:
                    print(f"âŒ {site_name}: íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e}")
            else:
                print(f"âŒ {filename} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê²½ë¡œ: {file_path})")
                
        return dataframes

    def debug_imdb_data(self, df: pd.DataFrame):
        """IMDB ë°ì´í„°ì˜ 'days_since_release' ì»¬ëŸ¼ì„ ì‹¬ì¸µ ë¶„ì„í•©ë‹ˆë‹¤."""
        if df is None or 'days_since_release' not in df.columns:
            print("IMDB ë°ì´í„° ë˜ëŠ” 'days_since_release' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        print("\nğŸ•µï¸â€â™‚ï¸ IMDB ë°ì´í„° ì‹¬ì¸µ ë¶„ì„ ì‹œì‘...")
        print("="*50)
        
        # 1. ë°ì´í„° íƒ€ì… ë° ê¸°ë³¸ ì •ë³´ í™•ì¸
        print("\n[1] ë°ì´í„°í”„ë ˆì„ ì •ë³´ (.info()):")
        df.info()

        # 2. 'days_since_release' ì»¬ëŸ¼ì˜ ê¸°ìˆ  í†µê³„
        print("\n[2] 'days_since_release' ê¸°ìˆ  í†µê³„ (.describe()):")
        print(df['days_since_release'].describe())

        # 3. 'days_since_release' ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ê³¼ ê°œìˆ˜ í™•ì¸ (ê°€ì¥ ì¤‘ìš”!)
        print("\n[3] 'days_since_release' ê³ ìœ ê°’ ë¶„í¬ (.value_counts()):")
        value_counts = df['days_since_release'].value_counts().sort_index()
        print(value_counts)
        
        print("="*50)
        print("ğŸ•µï¸â€â™‚ï¸ ë¶„ì„ ì¢…ë£Œ. ìœ„ 'ê³ ìœ ê°’ ë¶„í¬'ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\n")

        # ë§Œì•½ ê³ ìœ ê°’ì´ 2ê°œ ë¿ì´ë¼ë©´, ì´ê²ƒì´ ì›ì¸ì¼ ê°€ëŠ¥ì„±ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤.
        if len(value_counts) < 5:
             print("âš ï¸ ê²½ê³ : 'days_since_release'ì˜ ê³ ìœ ê°’ì´ ë§¤ìš° ì ìŠµë‹ˆë‹¤.")
             print("   ì´ê²ƒì´ ê·¸ë˜í”„ê°€ ìˆ˜ì§/ìˆ˜í‰ì„ ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ì›ì¸ì¼ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.")


    def process_time_data(self, df: pd.DataFrame, site_name: str) -> pd.DataFrame:
        """ì‹œê°„ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ì •ê·œí™”í•©ë‹ˆë‹¤."""
        print(f"\nğŸ“Š {site_name} ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        
        time_columns = ['days_since_release', 'date', 'timestamp', 'time', 'created_at', 'review_date']
        time_col = next((col for col in time_columns if col in df.columns), None)
        
        if time_col is None:
            print(f"âŒ {site_name}: ì‹œê°„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        try:
            if time_col == 'days_since_release':
                df['relative_time'] = pd.to_numeric(df[time_col], errors='coerce') * 24
                df.dropna(subset=['relative_time'], inplace=True)
                print(f"âœ… {site_name}: days_since_release ì»¬ëŸ¼ì„ ì‹œê°„ìœ¼ë¡œ ë³€í™˜ ì™„ë£Œ")
            else:
                df['datetime'] = pd.to_datetime(df[time_col], errors='coerce')
                df = df.dropna(subset=['datetime'])
                
                if len(df) == 0:
                    print(f"âŒ {site_name}: ìœ íš¨í•œ ì‹œê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return None
                
                df = df.sort_values('datetime')
                time_diff = df['datetime'] - df['datetime'].min()
                df['relative_time'] = time_diff.dt.total_seconds() / 3600
            
            if 'relative_time' not in df or df['relative_time'].isnull().all():
                 print(f"âŒ {site_name}: 'relative_time' ê³„ì‚°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                 return None

            total_hours = df['relative_time'].max()
            display_unit = "ì‹œê°„"
            display_total_time = total_hours
            if total_hours > 72:
                display_unit = "ì¼"
                display_total_time = total_hours / 24

            print(f"âœ… {site_name}: {len(df)} ê°œì˜ ìœ íš¨í•œ ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ")
            if 'datetime' in df:
                print(f"   - ì‹œê°„ ë²”ìœ„: {df['datetime'].min()} ~ {df['datetime'].max()}")
            print(f"   - ì´ ì‹œê°„: {display_total_time:.1f} {display_unit} ({total_hours:.1f} ì‹œê°„)")
            
            return df
            
        except Exception as e:
            print(f"âŒ {site_name}: ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e}")
            return None
    
    def create_time_distribution_plot(self, dataframes: Dict[str, pd.DataFrame]):
        """ì •ê·œí™”ëœ ëˆ„ì  ë¦¬ë·° ë¶„í¬ë¥¼ ë¹„êµí•˜ëŠ” ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        if not dataframes:
            print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        plt.figure(figsize=(15, 10))
        colors = {'IMDB': '#FF6B6B', 'Metacritic': '#4ECDC4', 'Rotten Tomatoes': '#45B7D1'}
        
        for site_name, df in dataframes.items():
            if df is None or len(df) < 2:
                print(f"âš ï¸ {site_name}: ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue
                
            df_sorted = df.sort_values('relative_time')
            
            time_range = df_sorted['relative_time'].max() - df_sorted['relative_time'].min()
            
            if time_range == 0:
                print(f"âš ï¸ {site_name}: ëª¨ë“  ë¦¬ë·°ì˜ ì‹œê°„ì´ ë™ì¼í•˜ì—¬ ì •ê·œí™”ëœ ë¶„í¬ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                normalized_time = [0, 100]
                cumulative_percent = [100, 100]
            else:
                normalized_time = (df_sorted['relative_time'] - df_sorted['relative_time'].min()) / time_range * 100
                cumulative_percent = np.arange(1, len(df_sorted) + 1) / len(df_sorted) * 100
            
            plt.plot(normalized_time, cumulative_percent,
                    label=f'{site_name} ({len(df)}ê°œ)',
                    color=colors.get(site_name, '#000000'),
                    linewidth=2.5,
                    alpha=0.8)
    
        plt.xlabel('ì •ê·œí™”ëœ ì‹œê°„ (%)', fontsize=12, fontweight='bold')
        plt.ylabel('ëˆ„ì  ë¦¬ë·° ë¹„ìœ¨ (%)', fontsize=12, fontweight='bold')
        plt.title('ì‚¬ì´íŠ¸ë³„ ì •ê·œí™”ëœ ëˆ„ì  ë¦¬ë·° ë¶„í¬ ë¹„êµ', fontsize=14, fontweight='bold', pad=20)
        plt.legend(fontsize=11, loc='best')
        plt.grid(True, which='both', linestyle='--', linewidth=0.5)
        plt.xlim(0, 100)
        plt.ylim(0, 100)
        
        plt.tight_layout()
        plt.show()
    
    def analyze_time_patterns(self, dataframes: Dict[str, pd.DataFrame]):
        """ì‹œê°„ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
        print("\nğŸ“ˆ ì‹œê°„ íŒ¨í„´ ë¶„ì„ ê²°ê³¼:")
        print("=" * 60)
        
        for site_name, df in dataframes.items():
            if df is None or len(df) == 0:
                continue
                
            print(f"\nğŸ¯ {site_name}:")
            
            total_time = df['relative_time'].max()
            total_reviews = len(df)
            
            if total_time <= 0:
                print("   - ì „ì²´ ë¦¬ë·° ê¸°ê°„ì´ 0 ë˜ëŠ” ìŒìˆ˜ì´ë¯€ë¡œ íŒ¨í„´ ë¶„ì„ì„ ìƒëµí•©ë‹ˆë‹¤.")
                continue

            avg_reviews_per_hour = total_reviews / total_time
            
            print(f"   - ì´ ë¦¬ë·° ìˆ˜: {total_reviews:,}ê°œ")
            print(f"   - ì´ ì‹œê°„: {total_time:.1f}ì‹œê°„")
            print(f"   - ì‹œê°„ë‹¹ í‰ê·  ë¦¬ë·°: {avg_reviews_per_hour:.2f}ê°œ")
            
            time_bins = np.arange(0, total_time + 1, 1)
            hist, bin_edges = np.histogram(df['relative_time'], bins=time_bins)
            
            if len(hist) > 0:
                peak_hour = bin_edges[np.argmax(hist)]
                peak_reviews = np.max(hist)
                print(f"   - í”¼í¬ ì‹œê°„: {peak_hour:.1f}ì‹œê°„ (ë¦¬ë·° {peak_reviews}ê°œ)")
            
            first_quarter_count = len(df[df['relative_time'] <= total_time * 0.25])
            last_quarter_count = len(df[df['relative_time'] >= total_time * 0.75])
            
            print(f"   - ì²« 25% ì‹œê°„: {first_quarter_count}ê°œ ë¦¬ë·° ({first_quarter_count/total_reviews*100:.1f}%)")
            print(f"   - ë§ˆì§€ë§‰ 25% ì‹œê°„: {last_quarter_count}ê°œ ë¦¬ë·° ({last_quarter_count/total_reviews*100:.1f}%)")
    
    def run_analysis(self):
        """ì „ì²´ ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print("ğŸ” ì‹œê³„ì—´ ë¦¬ë·° ë¶„ì„ ì‹œì‘...\n")
        
        dataframes = self.load_preprocessed_files()
        
        if not dataframes:
            print("âŒ ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        # IMDB ë°ì´í„°ê°€ ìˆë‹¤ë©´, ë””ë²„ê¹… í•¨ìˆ˜ë¥¼ ë¨¼ì € í˜¸ì¶œ
        if 'IMDB' in dataframes:
            self.debug_imdb_data(dataframes['IMDB'])
        
        processed_dataframes = {}
        for site_name, df in dataframes.items():
            processed_df = self.process_time_data(df, site_name)
            if processed_df is not None and not processed_df.empty:
                processed_dataframes[site_name] = processed_df
        
        if not processed_dataframes:
            print("âŒ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì‹œê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        self.analyze_time_patterns(processed_dataframes)
        
        print("\nğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...")
        self.create_time_distribution_plot(processed_dataframes)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    analyzer = TimeSeriesAnalyzer()
    analyzer.run_analysis()

if __name__ == "__main__":
    main()
