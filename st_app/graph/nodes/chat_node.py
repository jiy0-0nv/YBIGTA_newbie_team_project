from langchain_core.prompts import ChatPromptTemplate
from st_app.rag.llm import get_llm
from st_app.utils.state import AppState

def create_chat_prompt() -> ChatPromptTemplate:
    """ì˜ë„ íŒë‹¨ ë° ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸"""
    system_prompt = """ë‹¹ì‹ ì€ ì˜í™” ë¦¬ë·° ì•±ì˜ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ê³  ì‘ë‹µí•´ì£¼ì„¸ìš”:

1. "rag_review": ë¦¬ë·° ë¶„ì„, í‰ê°€, ì¶”ì²œ ìš”ì²­ì¸ ê²½ìš°
2. "subject_info": ì‘í’ˆ ì •ë³´, ì¤„ê±°ë¦¬, ê°ë…, ì¶œì—°ì§„ ìš”ì²­ì¸ ê²½ìš°  
3. "end": ì¼ë°˜ì ì¸ ëŒ€í™”, ì¸ì‚¬, ê°ì‚¬ í‘œí˜„ì¸ ê²½ìš°

ì‘ë‹µ í˜•ì‹:
- ë¨¼ì € ì˜ë„ ë¶„ë¥˜ë¥¼ í•œ ì¤„ë¡œ ì¶œë ¥ (ì˜ˆ: "ì˜ë„: rag_review")
- ê·¸ ë‹¤ìŒì— ì‹¤ì œ ì‘ë‹µì„ ì¶œë ¥

ì˜ˆì‹œ:
ì˜ë„: rag_review
íƒ‘ê±´ ë§¤ë²„ë¦­ì˜ ë¦¬ë·°ë¥¼ ë¶„ì„í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ê²€ìƒ‰ëœ ë¦¬ë·° ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°ê´€ì ì¸ ë¶„ì„ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.
"""

    return ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{user_input}")
    ])

def run(state: AppState) -> AppState:
    """Chat Node ì‹¤í–‰ - ì˜ë„ íŒë‹¨ ë° ì‘ë‹µ ìƒì„±"""
    llm = get_llm()
    prompt = create_chat_prompt()
    
    # LLM í˜¸ì¶œ
    response = llm.invoke(prompt.format(user_input=state["query"]))
    response_text = response.content
    
    # ì˜ë„ ì¶”ì¶œ
    if "ì˜ë„: rag_review" in response_text:
        state["next_action"] = "rag_review"
        print(f"ï¿½ï¿½ LLMì´ ì˜ë„ íŒë‹¨: rag_review")
    elif "ì˜ë„: subject_info" in response_text:
        state["next_action"] = "subject_info"
        print(f"ğŸ¯ LLMì´ ì˜ë„ íŒë‹¨: subject_info")
    else:
        state["next_action"] = "end"
        print(f"ï¿½ï¿½ LLMì´ ì˜ë„ íŒë‹¨: end")
    
    # ì‘ë‹µì—ì„œ ì˜ë„ ë¶€ë¶„ ì œê±°
    answer = response_text.split("ì˜ë„:")[1].strip() if "ì˜ë„:" in response_text else response_text
    state["answer"] = answer
    
    return state